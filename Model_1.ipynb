{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# üìÇ Importations n√©cessaires\n",
    "# ------------------------------------------\n",
    "\n",
    "# Biblioth√®ques standard Python\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Biblioth√®ques de manipulation de donn√©es\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "\n",
    "# Biblioth√®ques de visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    recall_score,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "\n",
    "# TensorFlow et Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ReduceLROnPlateau,\n",
    "    Callback\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Dense,\n",
    "    Input,\n",
    "    Dropout,\n",
    "    LayerNormalization,\n",
    "    Flatten,\n",
    "    Attention,\n",
    "    MultiHeadAttention,\n",
    "    GlobalAveragePooling1D,\n",
    "    Lambda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# üöÄ Chargement des donn√©es locales\n",
    "# ------------------------------------------\n",
    "\n",
    "# Fichiers d'entr√©e\n",
    "train_file = \"../Cleaned_data/mitbih_train_trimmed.csv\"\n",
    "test_file = \"../Cleaned_data/mitbih_test_trimmed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des donn√©es depuis ../Cleaned_data/mitbih_train_trimmed.csv...\n",
      "Nombre d'√©chantillons : 87553\n",
      "Distribution des classes : Counter({0: 72470, 4: 6431, 2: 5788, 1: 2223, 3: 641})\n",
      "Chargement des donn√©es depuis ../Cleaned_data/mitbih_test_trimmed.csv...\n",
      "Nombre d'√©chantillons : 21891\n",
      "Distribution des classes : Counter({0: 18117, 4: 1608, 2: 1448, 1: 556, 3: 162})\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# üì• Chargement des donn√©es avec fonction\n",
    "# ------------------------------------------\n",
    "\n",
    "def load_data(file_path):\n",
    "    print(f\"Chargement des donn√©es depuis {file_path}...\")\n",
    "    df = pd.read_csv(file_path)  # Chargement du fichier CSV\n",
    "    X = df.iloc[:, :-1].values  # Toutes les colonnes sauf la derni√®re (features)\n",
    "    y = df.iloc[:, -1].astype(int).values  # Derni√®re colonne = labels\n",
    "    X, y = shuffle(X, y, random_state=42)  # M√©lange al√©atoire des donn√©es\n",
    "    print(f\"Nombre d'√©chantillons : {len(X)}\")\n",
    "    print(\"Distribution des classes :\", Counter(y))  # Distribution des classes\n",
    "    return X, y\n",
    "\n",
    "# Charger les donn√©es en utilisant la fonction\n",
    "train_ecgs, train_labels = load_data(train_file)\n",
    "test_ecgs, test_labels = load_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# üîÑ Augmentation des donn√©es\n",
    "# ------------------------------------------\n",
    "def add_gaussian_noise(ecg, noise_level=0.01):\n",
    "    noise = np.random.normal(0, noise_level, len(ecg))\n",
    "    return ecg + noise\n",
    "\n",
    "def shift_signal(ecg, shift=10):\n",
    "    return np.roll(ecg, shift)\n",
    "\n",
    "def combine_augmentations(ecg, noise_level=0.01, shift=10):\n",
    "    return shift_signal(add_gaussian_noise(ecg, noise_level), shift)\n",
    "\n",
    "def augment_class_diverse(ecgs, deficit):\n",
    "    \"\"\"\n",
    "    Augmente une classe sp√©cifique en utilisant plusieurs techniques.\n",
    "    \"\"\"\n",
    "    augmented_ecgs = []\n",
    "    for i in range(deficit):\n",
    "        ecg = ecgs[i % len(ecgs)]  # R√©utiliser les √©chantillons si n√©cessaire\n",
    "        if i % 3 == 0:\n",
    "            augmented_ecgs.append(shift_signal(ecg))\n",
    "        elif i % 3 == 1:\n",
    "            augmented_ecgs.append(add_gaussian_noise(ecg))\n",
    "        else:\n",
    "            augmented_ecgs.append(combine_augmentations(ecg))\n",
    "    return augmented_ecgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# ‚ûó S√©parer les donn√©es par classes\n",
    "# ------------------------------------------\n",
    "\n",
    "def separate_sains_malades(ecgs, labels):\n",
    "    \"\"\"\n",
    "    S√©pare les donn√©es en deux cat√©gories : Sains (0) et Malades (1).\n",
    "    \"\"\"\n",
    "    sains = []\n",
    "    malades = []\n",
    "    for ecg, label in zip(ecgs, labels):\n",
    "        if label == 0:\n",
    "            sains.append(ecg)\n",
    "        else:  # Regroupe les classes 1, 2, 3, 4 en \"Malades\"\n",
    "            malades.append(ecg)\n",
    "    return sains, malades\n",
    "\n",
    "# S√©paration des donn√©es d'entra√Ænement\n",
    "sains_train, malades_train = separate_sains_malades(train_ecgs, train_labels)\n",
    "\n",
    "# Distribution initiale\n",
    "print(f\"Nombre de sujets sains : {len(sains_train)}\")\n",
    "print(f\"Nombre de sujets malades : {len(malades_train)}\")\n",
    "\n",
    "# √âtape 3 : Augmentation des donn√©es\n",
    "# Ajuster la taille cible pour √©quilibrer les classes\n",
    "final_group_size = max(len(sains_train), len(malades_train))  # Taille cible bas√©e sur la classe majoritaire\n",
    "\n",
    "# Augmentation pour les malades\n",
    "deficit_malades = final_group_size - len(malades_train)\n",
    "augmented_malades = augment_class_diverse(malades_train, deficit_malades)\n",
    "malades_train += augmented_malades\n",
    "\n",
    "# Augmentation pour les sains (si n√©cessaire)\n",
    "deficit_sains = final_group_size - len(sains_train)\n",
    "augmented_sains = augment_class_diverse(sains_train, deficit_sains)\n",
    "sains_train += augmented_sains\n",
    "\n",
    "print(f\"Apr√®s augmentation : {len(sains_train)} sujets sains, {len(malades_train)} sujets malades\")\n",
    "\n",
    "# Combiner les deux cat√©gories\n",
    "final_ecgs_train = sains_train + malades_train\n",
    "final_labels_train = [0] * len(sains_train) + [1] * len(malades_train)\n",
    "\n",
    "# M√©langer les donn√©es augment√©es\n",
    "final_ecgs_train, final_labels_train = shuffle(final_ecgs_train, final_labels_train, random_state=42)\n",
    "\n",
    "# √âtape 4 : R√©p√©tez pour les donn√©es de test\n",
    "sains_test, malades_test = separate_sains_malades(test_ecgs, test_labels)\n",
    "\n",
    "final_ecgs_test = sains_test + malades_test\n",
    "final_labels_test = [0] * len(sains_test) + [1] * len(malades_test)\n",
    "\n",
    "final_ecgs_test, final_labels_test = shuffle(final_ecgs_test, final_labels_test, random_state=42)\n",
    "\n",
    "# √âtape 5 : Visualisation des nouvelles distributions\n",
    "final_distribution_train = Counter(final_labels_train)\n",
    "final_distribution_test = Counter(final_labels_test)\n",
    "\n",
    "# Pie chart pour l'entra√Ænement\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(\n",
    "   [final_distribution_train[0], final_distribution_train[1]],\n",
    "   labels=[\"Sains\", \"Malades\"],\n",
    "   autopct='%1.1f%%',\n",
    "   startangle=90,\n",
    "   colors=['#C7E5D6', '#B8D8E8']\n",
    ")\n",
    "plt.title(\"Distribution des ECGs (Entra√Ænement)\")\n",
    "plt.show()\n",
    "\n",
    "# Pie chart pour le test\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(\n",
    "   [final_distribution_test[0], final_distribution_test[1]],\n",
    "   labels=[\"Sains\", \"Malades\"],\n",
    "   autopct='%1.1f%%',\n",
    "   startangle=90,\n",
    "   colors=['#C7E5D6', '#B8D8E8']\n",
    ")\n",
    "plt.title(\"Distribution des ECGs (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification des shapes des donn√©es initiales\n",
    "final_ecgs_train = np.array(final_ecgs_train)  # Conversion en array numpy\n",
    "final_ecgs_test = np.array(final_ecgs_test)    # Conversion en array numpy\n",
    "\n",
    "print(\"final_ecgs_train shape initial:\", final_ecgs_train.shape)\n",
    "print(\"final_ecgs_test shape initial:\", final_ecgs_test.shape)\n",
    "\n",
    "# 1. Normalisation des donn√©es (en s'assurant qu'elles sont en 2D)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape en 2D pour la normalisation\n",
    "final_ecgs_train = final_ecgs_train.reshape(final_ecgs_train.shape[0], -1)\n",
    "final_ecgs_test = final_ecgs_test.reshape(final_ecgs_test.shape[0], -1)\n",
    "\n",
    "# Normalisation\n",
    "final_ecgs_train = scaler.fit_transform(final_ecgs_train)\n",
    "final_ecgs_test = scaler.transform(final_ecgs_test)\n",
    "\n",
    "# Reshape pour compatibilit√© avec GRU (format 3D)\n",
    "final_ecgs_train = final_ecgs_train.reshape(-1, 182, 1)\n",
    "final_ecgs_test = final_ecgs_test.reshape(-1, 182, 1)\n",
    "\n",
    "# V√©rification des dimensions finales\n",
    "print(\"final_ecgs_train shape final:\", final_ecgs_train.shape)\n",
    "print(\"final_ecgs_test shape final:\", final_ecgs_test.shape)\n",
    "\n",
    "# Conversion des labels en tableaux NumPy\n",
    "final_labels_train = np.array(final_labels_train)\n",
    "final_labels_test = np.array(final_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback pour suivre le recall\n",
    "class RecallCallback(Callback):\n",
    "    def __init__(self, validation_data=None, training_data=None):\n",
    "        super(RecallCallback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.training_data = training_data\n",
    "        self.train_recalls = []\n",
    "        self.val_recalls = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Calcul du recall sur les donn√©es d'entra√Ænement\n",
    "        y_pred = self.model.predict(self.training_data[0])\n",
    "        y_pred_classes = (y_pred[:, 1] >= 0.5).astype(int)\n",
    "        train_recall = recall_score(self.training_data[1], y_pred_classes)\n",
    "        self.train_recalls.append(train_recall)\n",
    "        logs['recall'] = train_recall\n",
    "\n",
    "        # Calcul du recall sur les donn√©es de validation\n",
    "        if self.validation_data:\n",
    "            val_pred = self.model.predict(self.validation_data[0])\n",
    "            val_pred_classes = (val_pred[:, 1] >= 0.5).astype(int)\n",
    "            val_recall = recall_score(self.validation_data[1], val_pred_classes)\n",
    "            self.val_recalls.append(val_recall)\n",
    "            logs['val_recall'] = val_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param√®tres du mod√®le\n",
    "input_shape = final_ecgs_train.shape[1:]  # Ajust√© selon les donn√©es reshaped\n",
    "gru_units = 64\n",
    "dropout_rate = 0.2\n",
    "num_classes = 2\n",
    "\n",
    "# Modification du bloc GRU avec attention\n",
    "def gru_attention_block(inputs, gru_units, dropout_rate):\n",
    "    # Premi√®re couche GRU\n",
    "    x = GRU(gru_units, return_sequences=True)(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Deuxi√®me couche GRU\n",
    "    x = GRU(gru_units * 2, return_sequences=True)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Attention\n",
    "    attention_output = Attention()([x, x])\n",
    "    return attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des couches\n",
    "inputs = Input(shape=input_shape)\n",
    "x = gru_attention_block(inputs, gru_units, dropout_rate)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = LayerNormalization()(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# Cr√©ation et compilation du mod√®le\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=8,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.2,     # R√©duire √† 0.5 pour une d√©croissance plus douce\n",
    "    patience=4,     # Augmenter √† 6-8 pour plus de stabilit√©\n",
    "    verbose=1,\n",
    "    min_lr=1e-7,    # Ajuster √† 1e-6\n",
    "    cooldown=2  \n",
    ")\n",
    "\n",
    "# Initialisation du callback de recall\n",
    "recall_callback = RecallCallback(\n",
    "    validation_data=(final_ecgs_test, final_labels_test),\n",
    "    training_data=(final_ecgs_train, final_labels_train)\n",
    ")\n",
    "\n",
    "# Calculer la distribution originale (avant regroupement en 2 classes)\n",
    "original_distribution = Counter([label for label in final_labels_train])\n",
    "print(\"Distribution originale brute:\", original_distribution)\n",
    "\n",
    "# Calculer la somme des malades (classes 1-4)\n",
    "nb_sains = original_distribution[0]  # classe 0\n",
    "nb_malades = sum(original_distribution[i] for i in range(1, 5))  # somme des classes 1-4\n",
    "\n",
    "binary_distribution = {0: nb_sains, 1: nb_malades}\n",
    "print(\"Distribution binaire:\", binary_distribution)\n",
    "\n",
    "# Calculer les poids\n",
    "max_samples = max(binary_distribution.values())\n",
    "class_weights = {\n",
    "    label: max_samples/count\n",
    "    for label, count in binary_distribution.items()\n",
    "}\n",
    "\n",
    "print(\"Poids par classe:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration des ensembles d'entra√Ænement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    final_ecgs_train,\n",
    "    final_labels_train,\n",
    "    test_size=0.2,  # 20% pour validation\n",
    "    random_state=42,\n",
    "    stratify=final_labels_train\n",
    ")\n",
    "\n",
    "# Entra√Ænement\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_val, y_val),  # Utilisation des donn√©es de validation\n",
    "    callbacks=[early_stopping, reduce_lr, recall_callback],\n",
    "    verbose=1,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le mod√®le\n",
    "dump(scaler, 'ecg_scaler_m1.joblib')\n",
    "model.save('ecg_model_m1.h5')\n",
    "\n",
    "# Sauvegarder l'historique d'entra√Ænement\n",
    "history_dict = history.history\n",
    "np.save('training_history.npy', history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation des graphiques de loss et accuracy\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot de la loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('√âvolution de la fonction de perte')\n",
    "plt.xlabel('√âpoque')\n",
    "plt.ylabel('Perte')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot de l'accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('√âvolution de l\\'accuracy')\n",
    "plt.xlabel('√âpoque')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot du recall (nouveau)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(recall_callback.train_recalls, label='Training Recall')\n",
    "plt.plot(recall_callback.val_recalls, label='Validation Recall')\n",
    "plt.title('√âvolution du Recall')\n",
    "plt.xlabel('√âpoque')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher les valeurs finales\n",
    "print(\"\\nR√©sum√© des performances finales :\")\n",
    "print(f\"Perte finale sur l'ensemble d'entra√Ænement : {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Perte finale sur l'ensemble de validation : {history.history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Accuracy finale sur l'ensemble d'entra√Ænement : {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Accuracy finale sur l'ensemble de validation : {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Recall final sur l'ensemble d'entra√Ænement : {recall_callback.train_recalls[-1]:.4f}\")\n",
    "print(f\"Recall final sur l'ensemble de validation : {recall_callback.val_recalls[-1]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions\n",
    "y_pred_proba = model.predict(final_ecgs_test)[:, 1]\n",
    "y_pred = np.argmax(model.predict(final_ecgs_test), axis=-1)\n",
    "\n",
    "# M√©triques de base\n",
    "accuracy_test = accuracy_score(final_labels_test, y_pred)\n",
    "print(f\"\\nAccuracy sur le dataset de test : {accuracy_test:.4f}\")\n",
    "print(\"\\nRapport d√©taill√© :\")\n",
    "print(classification_report(final_labels_test, y_pred, target_names=['Classe 0', 'Classe 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(final_labels_test, y_pred)\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=['Classe 0', 'Classe 1'],\n",
    "    yticklabels=['Classe 0', 'Classe 1']\n",
    ")\n",
    "plt.xlabel('Pr√©dictions')\n",
    "plt.ylabel('Vrais Labels')\n",
    "plt.title('Matrice de Confusion')\n",
    "plt.show()\n",
    "\n",
    "# % Pour la premi√®re matrice de confusion\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "sns.heatmap(\n",
    "    cm_percentage,\n",
    "    annot=True,\n",
    "    fmt='.1f',  # Format avec 1 d√©cimale\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=['Classe 0', 'Classe 1'],\n",
    "    yticklabels=['Classe 0', 'Classe 1']\n",
    ")\n",
    "plt.xlabel('Pr√©dictions')\n",
    "plt.ylabel('Vrais Labels')\n",
    "plt.title('Matrice de Confusion (%)')\n",
    "plt.show()\n",
    "\n",
    "# % Pour la matrice de confusion (pour le total)\n",
    "plt.figure(figsize=(8, 6))\n",
    "total = cm.sum()\n",
    "cm_percentage = (cm / total) * 100  # Division par le total global\n",
    "\n",
    "sns.heatmap(\n",
    "    cm_percentage,\n",
    "    annot=True,\n",
    "    fmt='.1f',  # Format avec 1 d√©cimale\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=['Classe 0', 'Classe 1'],\n",
    "    yticklabels=['Classe 0', 'Classe 1']\n",
    ")\n",
    "plt.xlabel('Pr√©dictions')\n",
    "plt.ylabel('Vrais Labels')\n",
    "plt.title('Matrice de Confusion (% du total)')\n",
    "plt.show()\n",
    "\n",
    "# Courbe ROC\n",
    "fpr, tpr, thresholds = roc_curve(final_labels_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Optimisation du seuil\n",
    "precisions = []\n",
    "recalls = []\n",
    "specificities = []\n",
    "f1_scores = []\n",
    "thresholds_metrics = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(final_labels_test, y_pred_threshold).ravel()\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    specificities.append(specificity)\n",
    "    f1_scores.append(f1)\n",
    "    thresholds_metrics.append(threshold)\n",
    "\n",
    "# DataFrame des m√©triques\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Threshold': thresholds_metrics,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'Specificity': specificities,\n",
    "    'F1': f1_scores\n",
    "})\n",
    "\n",
    "# Trouver le seuil optimal\n",
    "min_specificity = 0.95  # Plus strict sur la sp√©cificit√© (pr√©serve classe 0)\n",
    "min_recall_0 = 0.98    # Maintenir un bon recall pour la classe 0\n",
    "\n",
    "valid_thresholds = metrics_df[\n",
    "    (metrics_df['Specificity'] >= min_specificity) &\n",
    "    ((1 - metrics_df['Precision']) <= 0.1)\n",
    "]\n",
    "\n",
    "if len(valid_thresholds) > 0:\n",
    "    optimal_threshold = valid_thresholds.loc[valid_thresholds['Recall'].idxmax(), 'Threshold']\n",
    "else:\n",
    "    print(\"Aucun seuil ne satisfait les crit√®res, utilisation du seuil par d√©faut 0.5\")\n",
    "    optimal_threshold = 0.5\n",
    "\n",
    "print(f\"\\nSeuil optimal : {optimal_threshold:.3f}\")\n",
    "\n",
    "# Avant d'appliquer le seuil, affichons les m√©triques pour plusieurs seuils\n",
    "test_thresholds = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, optimal_threshold]\n",
    "print(\"\\nComparaison des diff√©rents seuils :\")\n",
    "for threshold in test_thresholds:\n",
    "    y_pred_test = (y_pred_proba >= threshold).astype(int)\n",
    "    print(f\"\\nSeuil : {threshold:.3f}\")\n",
    "    print(classification_report(final_labels_test, y_pred_test, target_names=['Classe 0', 'Classe 1']))\n",
    "\n",
    "# Appliquer le seuil optimal\n",
    "y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Afficher les r√©sultats avec le seuil optimal\n",
    "print(\"\\nR√©sultats avec le seuil optimal :\")\n",
    "print(classification_report(final_labels_test, y_pred_optimal, target_names=['Classe 0', 'Classe 1']))\n",
    "\n",
    "# Nouvelle matrice de confusion avec le seuil optimal\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm_optimal = confusion_matrix(final_labels_test, y_pred_optimal)\n",
    "sns.heatmap(\n",
    "    cm_optimal,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=['Classe 0', 'Classe 1'],\n",
    "    yticklabels=['Classe 0', 'Classe 1']\n",
    ")\n",
    "plt.xlabel('Pr√©dictions')\n",
    "plt.ylabel('Vrais Labels')\n",
    "plt.title('Matrice de Confusion (Seuil Optimal)')\n",
    "plt.show()\n",
    "\n",
    "# Matrice de confusion en pourcentage\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm_optimal_percentage = cm_optimal.astype('float') / cm_optimal.sum(axis=1)[:, np.newaxis] * 100\n",
    "sns.heatmap(\n",
    "    cm_optimal_percentage,\n",
    "    annot=True,\n",
    "    fmt='.1f',\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=['Classe 0', 'Classe 1'],\n",
    "    yticklabels=['Classe 0', 'Classe 1']\n",
    ")\n",
    "plt.xlabel('Pr√©dictions')\n",
    "plt.ylabel('Vrais Labels')\n",
    "plt.title('Matrice de Confusion avec Seuil Optimal (%)')\n",
    "plt.show()\n",
    "\n",
    "# Courbe d'√©volution du recall\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds_metrics, recalls, label='Recall', color='blue')\n",
    "plt.axvline(x=optimal_threshold, color='red', linestyle='--', label='Seuil optimal')\n",
    "plt.xlabel('Seuil')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('√âvolution du Recall en fonction du seuil')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Courbe ROC avec seuil optimal\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Tracer la courbe ROC\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "# Trouver les coordonn√©es correspondantes au seuil optimal\n",
    "optimal_idx = np.argmin(np.abs(thresholds - optimal_threshold))  # Index du seuil optimal\n",
    "optimal_fpr = fpr[optimal_idx]\n",
    "optimal_tpr = tpr[optimal_idx]\n",
    "\n",
    "# Ajouter un point pour le seuil optimal\n",
    "plt.scatter(optimal_fpr, optimal_tpr, color='red', label=f'Seuil optimal ({optimal_threshold:.2f})', zorder=5)\n",
    "\n",
    "# Ajuster les limites et ajouter des labels\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbe ROC avec seuil optimal')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
